import feedparser
import re
from datetime import datetime

# List of RSS URLs to fetch / Add if required
urls = [
    'https://www.bleepingcomputer.com/feed/',
    'https://feeds.feedburner.com/TheHackersNews',
    'https://www.cisa.gov/cybersecurity-advisories/cybersecurity-advisories.xml',
    'https://www.theregister.com/security/patches/headlines.atom',
]

cve_numbers = []  # A list to store all the unique CVE numbers found in the feeds

for url in urls:
    feed = feedparser.parse(url)
    for entry in feed.entries:
        # Extract CVE numbers from the description using regular expressions
        cve_regex = r'CVE-\d{4}-\d{5}'
        cve_numbers += re.findall(cve_regex, entry.description)

# Remove duplicates from the list
cve_numbers = list(set(cve_numbers))

if cve_numbers:
    # Add quotes around each CVE number so it's easy for security software to ingest
    cve_numbers = [f'"{cve}"' for cve in cve_numbers]
    output = "CVEs found in Security Blogs: " + ", ".join(cve_numbers) + "\n\n"
else:
    output = "No CVE numbers found in the feeds."

# Get the current date and time
now = datetime.now()
dt_string = now.strftime("\n\nDate and Time: %Y-%m-%d %H:%M:%S")

# Add the total number of unique CVEs to the output
output += f"Total number of unique CVEs found: {len(cve_numbers)}"

# Add the date and time to the output
output += dt_string

# Open the output file in append mode and write the output to the file
with open('output.txt', 'a') as f:
    f.write(output + "\n")
